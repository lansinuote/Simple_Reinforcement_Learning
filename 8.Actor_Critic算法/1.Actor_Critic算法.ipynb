{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/gym/core.py:26: UserWarning: \u001b[33mWARN: Gym minimally supports python 3.6 as the python foundation not longer supports the version, please update your version to 3.7+\u001b[0m\n",
      "  \"Gym minimally supports python 3.6 as the python foundation not longer supports the version, please update your version to 3.7+\"\n",
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  f\"The environment {id} is out of date. You should consider \"\n",
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  \"The argument mode in render method is deprecated; \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#创建环境\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "\n",
    "\n",
    "#打印游戏\n",
    "def show():\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4340, 0.5660],\n",
       "         [0.3047, 0.6953]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.3946],\n",
       "         [0.3271]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#定义模型\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 2),\n",
    "    torch.nn.Softmax(dim=1),\n",
    ")\n",
    "\n",
    "model_td = sequential = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 1),\n",
    ")\n",
    "\n",
    "model(torch.randn(2, 4)), model_td(torch.randn(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "#得到一个动作\n",
    "def get_action(state):\n",
    "    state = torch.FloatTensor(state).reshape(1, 4)\n",
    "    #[1, 4] -> [1, 2]\n",
    "    prob = model(state)\n",
    "\n",
    "    #根据概率选择一个动作\n",
    "    action = random.choices(range(2), weights=prob[0].tolist(), k=1)[0]\n",
    "\n",
    "    return action\n",
    "\n",
    "\n",
    "get_action([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/cpu/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811701593/work/torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0451,  0.0146,  0.0370,  0.0127],\n",
       "         [-0.0448,  0.2092,  0.0372, -0.2681],\n",
       "         [-0.0406,  0.0135,  0.0319,  0.0361],\n",
       "         [-0.0403, -0.1820,  0.0326,  0.3387],\n",
       "         [-0.0440, -0.3776,  0.0394,  0.6414],\n",
       "         [-0.0515, -0.1830,  0.0522,  0.3614],\n",
       "         [-0.0552, -0.3789,  0.0594,  0.6701],\n",
       "         [-0.0627, -0.5748,  0.0728,  0.9809],\n",
       "         [-0.0742, -0.7708,  0.0925,  1.2955],\n",
       "         [-0.0897, -0.9669,  0.1184,  1.6157],\n",
       "         [-0.1090, -0.7734,  0.1507,  1.3621],\n",
       "         [-0.1245, -0.9701,  0.1779,  1.6979]]),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " tensor([[1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1]]),\n",
       " tensor([[-0.0448,  0.2092,  0.0372, -0.2681],\n",
       "         [-0.0406,  0.0135,  0.0319,  0.0361],\n",
       "         [-0.0403, -0.1820,  0.0326,  0.3387],\n",
       "         [-0.0440, -0.3776,  0.0394,  0.6414],\n",
       "         [-0.0515, -0.1830,  0.0522,  0.3614],\n",
       "         [-0.0552, -0.3789,  0.0594,  0.6701],\n",
       "         [-0.0627, -0.5748,  0.0728,  0.9809],\n",
       "         [-0.0742, -0.7708,  0.0925,  1.2955],\n",
       "         [-0.0897, -0.9669,  0.1184,  1.6157],\n",
       "         [-0.1090, -0.7734,  0.1507,  1.3621],\n",
       "         [-0.1245, -0.9701,  0.1779,  1.6979],\n",
       "         [-0.1439, -0.7774,  0.2119,  1.4654]]),\n",
       " tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data():\n",
    "    states = []\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    next_states = []\n",
    "    overs = []\n",
    "\n",
    "    #初始化游戏\n",
    "    state = env.reset()\n",
    "\n",
    "    #玩到游戏结束为止\n",
    "    over = False\n",
    "    while not over:\n",
    "        #根据当前状态得到一个动作\n",
    "        action = get_action(state)\n",
    "\n",
    "        #执行动作,得到反馈\n",
    "        next_state, reward, over, _ = env.step(action)\n",
    "\n",
    "        #记录数据样本\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        next_states.append(next_state)\n",
    "        overs.append(over)\n",
    "\n",
    "        #更新游戏状态,开始下一个动作\n",
    "        state = next_state\n",
    "\n",
    "    #[b, 4]\n",
    "    states = torch.FloatTensor(states).reshape(-1, 4)\n",
    "    #[b, 1]\n",
    "    rewards = torch.FloatTensor(rewards).reshape(-1, 1)\n",
    "    #[b, 1]\n",
    "    actions = torch.LongTensor(actions).reshape(-1, 1)\n",
    "    #[b, 4]\n",
    "    next_states = torch.FloatTensor(next_states).reshape(-1, 4)\n",
    "    #[b, 1]\n",
    "    overs = torch.LongTensor(overs).reshape(-1, 1)\n",
    "\n",
    "    return states, rewards, actions, next_states, overs\n",
    "\n",
    "\n",
    "get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "\n",
    "def test(play):\n",
    "    #初始化游戏\n",
    "    state = env.reset()\n",
    "\n",
    "    #记录反馈值的和,这个值越大越好\n",
    "    reward_sum = 0\n",
    "\n",
    "    #玩到游戏结束为止\n",
    "    over = False\n",
    "    while not over:\n",
    "        #根据当前状态得到一个动作\n",
    "        action = get_action(state)\n",
    "\n",
    "        #执行动作,得到反馈\n",
    "        state, reward, over, _ = env.step(action)\n",
    "        reward_sum += reward\n",
    "\n",
    "        #打印动画\n",
    "        if play and random.random() < 0.2:  #跳帧\n",
    "            display.clear_output(wait=True)\n",
    "            show()\n",
    "\n",
    "    return reward_sum\n",
    "\n",
    "\n",
    "test(play=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 8251,
     "status": "ok",
     "timestamp": 1650011468229,
     "user": {
      "displayName": "Sam Lu",
      "userId": "15789059763790170725"
     },
     "user_tz": -480
    },
    "id": "BQXVYW2T_DcQ",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 21.4\n",
      "100 20.6\n",
      "200 42.3\n",
      "300 64.1\n",
      "400 147.3\n",
      "500 158.9\n",
      "600 195.3\n",
      "700 190.2\n",
      "800 200.0\n",
      "900 200.0\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    optimizer_td = torch.optim.Adam(model_td.parameters(), lr=1e-2)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    #玩N局游戏,每局游戏训练一次\n",
    "    for i in range(1000):\n",
    "        #玩一局游戏,得到数据\n",
    "        #states -> [b, 4]\n",
    "        #rewards -> [b, 1]\n",
    "        #actions -> [b, 1]\n",
    "        #next_states -> [b, 4]\n",
    "        #overs -> [b, 1]\n",
    "        states, rewards, actions, next_states, overs = get_data()\n",
    "\n",
    "        #计算values和targets\n",
    "        #[b, 4] -> [b ,1]\n",
    "        values = model_td(states)\n",
    "\n",
    "        #[b, 4] -> [b ,1]\n",
    "        targets = model_td(next_states) * 0.98\n",
    "        #[b ,1] * [b ,1] -> [b ,1]\n",
    "        targets *= (1 - overs)\n",
    "        #[b ,1] + [b ,1] -> [b ,1]\n",
    "        targets += rewards\n",
    "\n",
    "        #时序差分误差\n",
    "        #[b ,1] - [b ,1] -> [b ,1]\n",
    "        delta = (targets - values).detach()\n",
    "\n",
    "        #重新计算对应动作的概率\n",
    "        #[b, 4] -> [b ,2]\n",
    "        probs = model(states)\n",
    "        #[b ,2] -> [b ,1]\n",
    "        probs = probs.gather(dim=1, index=actions)\n",
    "\n",
    "        #根据策略梯度算法的导函数实现\n",
    "        #只是把公式中的reward_sum替换为了时序差分的误差\n",
    "        #[b ,1] * [b ,1] -> [b ,1] -> scala\n",
    "        loss = (-probs.log() * delta).mean()\n",
    "\n",
    "        #时序差分的loss就是简单的value和target求mse loss即可\n",
    "        loss_td = loss_fn(values, targets.detach())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer_td.zero_grad()\n",
    "        loss_td.backward()\n",
    "        optimizer_td.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            test_result = sum([test(play=False) for _ in range(10)]) / 10\n",
    "            print(i, test_result)\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(play=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "第9章-策略梯度算法.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
